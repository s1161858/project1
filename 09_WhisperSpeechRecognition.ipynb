{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s1161858/project1/blob/main/09_WhisperSpeechRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbkeLRGu8t_j"
      },
      "source": [
        "# Speech Recognition with Whisper\n",
        "\n",
        "### By AIDCEC, EDUHK\n",
        "\n",
        "\n",
        "Speech recognition (i.e. speech-to-text recognition) tools are now common in everyday life. In this Colab notebook, we will introduce OpenAI's Whisper for transcribing audio files and a few other packages for audio processing.\n",
        "\n",
        "GitHub page: https://github.com/openai/whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ptACYLX_76s"
      },
      "source": [
        "## 1. Install and Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYkwW8uoAgdD"
      },
      "source": [
        "Install Whisper and FFmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Btsref_zvthm",
        "outputId": "54b61df7-5a54-45e3-f585-9b952031106b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-8gz8o0nj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-8gz8o0nj\n",
            "  Resolved https://github.com/openai/whisper.git to commit c0d2f624c09dc18e709e37c2ad90c039a4eb72a2\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper==20250625) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper==20250625) (75.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper==20250625) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper==20250625) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper==20250625) (1.11.1.6)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20250625) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper==20250625) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper==20250625) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VBabkGK3T3Q",
        "outputId": "62462c21-4a17-4793-99fd-a2206f21b88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Connecting to security.ub\u001b[0m\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "42 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDr1iIUmfpzN"
      },
      "source": [
        "Import **os** library to navigate the file system and suppress warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJe6l0mP-LVJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0LsjANBO-ytV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCDSQgGHHCed"
      },
      "source": [
        "## 2. Read Audio File Or/And Record Your Audio File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIKVFZi-CCZX"
      },
      "source": [
        "###Choice (A): Test with Pre-recorded Audio Files\n",
        "\n",
        "You could find the audio from here:\n",
        "Language | Corpus website\n",
        "-------------------|------------------\n",
        "English | https://corpus.eduhk.hk/english_speech_corpus/\n",
        " | https://corpus.eduhk.hk/esl_learner_corpus/\n",
        "Putonghua | https://corpus.eduhk.hk/pth_learner_corpus/\n",
        "Cantonese | https://corpus.eduhk.hk/cantonese/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we use the audio file \"250231.mp3\" as an example, which contains a recording of the phrase \"It's on me\" in English.\n",
        "\n",
        "****Remember to upload the file \"250231.mp3\" to the \"Files\" before running the code below.**"
      ],
      "metadata": {
        "id": "6nMu2qQZ_oKQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "pBhcvouTHCAm",
        "outputId": "c9c32e38-f5ae-4809-cc3b-75761a04444c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from IPython.display import Audio\n",
        "Audio('/content/250231.mp3') #change the file name here if you have uploaded other audio files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to try on your own audio file, upload the file, change code in the above block and rerun it."
      ],
      "metadata": {
        "id": "HmpeGne0BFal"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5niOMzBJ6FMo"
      },
      "source": [
        "###Choice (B): Record Your Own Audio Files\n",
        "\n",
        "You could record your own voice in Colab with \"GoogleAudio\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TkV2cFiilEL",
        "outputId": "73d36d6c-4eba-4b20-9add-4943ab04f909"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: GoogleAudio==0.0.3 in /usr/local/lib/python3.12/dist-packages (0.0.3)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.12/dist-packages (from GoogleAudio==0.0.3) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python->GoogleAudio==0.0.3) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install GoogleAudio==0.0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code, allow the use of microphone in the browser, then re-run the following code. After recording, press the button \"Recording... press to stop\" to stop recording.\n",
        "\n",
        "****If the code cannot run, try running all code again, or refresh the page and try again.**"
      ],
      "metadata": {
        "id": "S48OJRFvAX-s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "id": "Rs8tb6z9inRb",
        "outputId": "7a047bbc-f01b-4f6a-a5a6-b1f6fc6bc3d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from googleaudio import colabaudio as agoogle #import modules\n",
        "my_audio_name='my_audio_123.wav' # file audio name, change before next recording if you want to keep the old file\n",
        "my_audio,sample_rate=agoogle.get_audio() #read audio data and sample rate\n",
        "agoogle.saveaudio(my_audio_name,my_audio,sample_rate)  # save it"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want record and keep the audio file, rename the audio name in the block above every time after recording."
      ],
      "metadata": {
        "id": "q0lQkB2qJ2QC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt1CFkehCoyl"
      },
      "source": [
        "## 3. Transcribe a Single Audio File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm-eqYLi8acz"
      },
      "source": [
        "**Model selection**\n",
        "\n",
        "There are 5 pre-trained options to play with:\n",
        "\n",
        "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
        "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
        "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
        "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
        " | small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
        "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
        "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |\n",
        "\n",
        "**Note:** \\\n",
        "FP16 and FP32 are floating-point precision formats. GPU will automatically adopt FP16. \\\n",
        "For CPU runtime, add `--fp16 False` to set FP16 False as CPU only support FP32, not FP16."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btwRFD4Nv73I"
      },
      "source": [
        "**Transcribe the File from Choice (A): Pre-recorded Audio Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JeCI9Qo6Qxm",
        "outputId": "2b922095-54c8-495b-bfb3-448fe5ec1f90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:01<00:00, 83.8MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:02.000]  It's on me.\n"
          ]
        }
      ],
      "source": [
        "!whisper \"/content/250231.mp3\" --model base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VjmpmOXJuTv"
      },
      "source": [
        "**Transcribe the File from Choice (B): You Own Audio Files**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXwhF59sjECx",
        "outputId": "33382869-68f8-4c92-c1a8-32e75dc77b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:02.000]  Bye bye bye bye bye bye\n"
          ]
        }
      ],
      "source": [
        "!whisper \"/content/my_audio_123.wav\" --model base --fp16 False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KoIRhjT13vC",
        "outputId": "ef15594b-4004-4f7f-ac20-7d951d2d7633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:01.480]  Why, why, why, why, why?\n"
          ]
        }
      ],
      "source": [
        "!whisper \"/content/my_audio_123.wav\" --model large --fp16 False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pMk3zKiGOX9"
      },
      "source": [
        "A variety of output files (json, srt, tsv, txt and vtt) can be found in the file system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHxyJpa5Poa"
      },
      "source": [
        "## 4. Transcribe Youtube Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD3AMocvj323"
      },
      "source": [
        "Dowload Youtube videos with **yt-dlp**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihptwyXN4SPX",
        "outputId": "7fb5184d-9190-4bdb-adf8-2ec51992e862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2025.10.22-py3-none-any.whl.metadata (176 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.10.22-py3-none-any.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.10.22\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-TmmkfXAbP3"
      },
      "source": [
        "**Example 1: English Video**\n",
        "\n",
        "ChatGPT: Are humans still smarter than AI? - BBC News \\\n",
        "https://www.youtube.com/watch?v=NR1Tvxaiu2Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHZ1mQAs4znK",
        "outputId": "661bfb60-1688-45b2-9510-69f4093bc1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=NR1Tvxaiu2Y\n",
            "[youtube] NR1Tvxaiu2Y: Downloading webpage\n",
            "[youtube] NR1Tvxaiu2Y: Downloading android sdkless player API JSON\n",
            "[youtube] NR1Tvxaiu2Y: Downloading tv client config\n",
            "[youtube] NR1Tvxaiu2Y: Downloading tv player API JSON\n",
            "[youtube] NR1Tvxaiu2Y: Downloading web safari player API JSON\n",
            "[youtube] NR1Tvxaiu2Y: Downloading player 87644c66-main\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] Falling back to generic n function search\n",
            "         player = https://www.youtube.com/s/player/87644c66/player_ias.vflset/en_US/base.js\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] NR1Tvxaiu2Y: nsig extraction failed: Some formats may be missing\n",
            "         n = gvcojeHQcVgC8A4aizS ; player = https://www.youtube.com/s/player/87644c66/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] NR1Tvxaiu2Y: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "\u001b[0;33mWARNING:\u001b[0m [youtube] NR1Tvxaiu2Y: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "[youtube] NR1Tvxaiu2Y: Downloading m3u8 information\n",
            "[info] NR1Tvxaiu2Y: Downloading 1 format(s): 251\n",
            "[download] Sleeping 4.00 seconds as required by the site...\n",
            "[download] Destination: audio1.webm\n",
            "\u001b[K[download] 100% of    1.98MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m4.77MiB/s\u001b[0m\n",
            "[ExtractAudio] Destination: audio1.mp3\n",
            "Deleting original file audio1.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "if (os.path.exists(\"/content/audio1.mp3\")):\n",
        "  os.remove(\"/content/audio1.mp3\")\n",
        "else:\n",
        "  pass\n",
        "!yt-dlp -x --audio-format mp3 --output \"audio1.mp3\" https://www.youtube.com/watch?v=NR1Tvxaiu2Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQFQGHuz_I8H",
        "outputId": "564b81f4-f7f4-45c7-b2cd-5e9e6ca016c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:04.240]  I'm designed to generate responses to questions based on my understanding of natural language.\n",
            "[00:04.240 --> 00:07.520]  You've probably used it, you've definitely heard of it.\n",
            "[00:07.520 --> 00:11.680]  Chat GPT has been held as a game changer. It can write songs.\n",
            "[00:11.680 --> 00:15.520]  Melissa's got a vision. A story she wants to tell.\n",
            "[00:15.520 --> 00:19.840]  Define quantum mechanics as well as explaining how I could boost my intelligence.\n",
            "[00:20.480 --> 00:23.280]  Google has also released a competitor, Bard.\n",
            "[00:23.920 --> 00:29.440]  Impressive, right? Computers seem to be rapidly outsmarting their creators.\n",
            "[00:29.440 --> 00:31.120]  But is that really true?\n",
            "[00:31.120 --> 00:37.520]  We have a lot of very sophisticated algorithms, but basically what these algorithms are doing is\n",
            "[00:37.520 --> 00:42.480]  getting a lot of information from the internet, so they're capable of, you know,\n",
            "[00:42.480 --> 00:45.280]  addressing all kind of situation, all kind of questions.\n",
            "[00:45.280 --> 00:50.800]  They're not very good in adapting. They're not very good in learning something,\n",
            "[00:50.800 --> 00:56.160]  in some scenario, in some environment, and then generalize it to a different environment.\n",
            "[00:56.160 --> 00:59.440]  And this is something that children and infants are very good at.\n",
            "[01:00.160 --> 01:03.680]  It's our adaptability that keeps us one step ahead of AI.\n",
            "[01:04.320 --> 01:09.760]  From birth, our brain adapts and molds itself to the environment in a very efficient way.\n",
            "[01:09.760 --> 01:14.400]  Oh, we're very, very far away from having computers that are very adaptable, I think.\n",
            "[01:14.400 --> 01:16.720]  Maybe we'll figure it out how that happens.\n",
            "[01:17.280 --> 01:21.120]  But the fact that these algorithms don't have, usually don't have bodies.\n",
            "[01:21.120 --> 01:26.080]  And even if they have bodies, their robots, their robots don't, their body doesn't change.\n",
            "[01:26.080 --> 01:29.600]  Their experiences are much less flexible.\n",
            "[01:29.600 --> 01:35.520]  There's a lot less variability compared to children and infants that need to adapt to different\n",
            "[01:35.520 --> 01:42.640]  body every day. The truth is, neuroscientists still don't know exactly how or why our brain is\n",
            "[01:42.640 --> 01:48.400]  so good at adapting. And until we know better how this process works, computers are not going to\n",
            "[01:48.400 --> 01:54.240]  come anywhere close. And luckily, chat GPT knows the limits of its own virtual mind.\n",
            "[01:54.240 --> 01:58.160]  They cannot replicate the full range of human intelligence.\n"
          ]
        }
      ],
      "source": [
        "!whisper \"/content/audio1.mp3\" --model base --fp16 False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbtVwlc6sGz1"
      },
      "source": [
        "**Example 2: Non-English Video**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeswzECQoVph"
      },
      "source": [
        "EdUHK AIDCEC 2526 MSc AIEP - Postgraduate Student Interview Part 1 \\\n",
        "https://www.youtube.com/watch?v=EKkZ8yVu2yg\n",
        "\n",
        "\n",
        "**You can also try with other links:** \\\n",
        "EdUHK AIDCEC 2526 MSc AIEP - Postgraduate Student Interview Part 2 \\\n",
        "https://www.youtube.com/watch?v=tZcThqxgfmg\n",
        "\n",
        "開心香港 \\\n",
        "https://www.youtube.com/watch?v=VpMve52OpQQ\n",
        "\n",
        "香港教育大學「看動畫．學歷史」第一集：孔子(普通話) \\\n",
        "https://www.youtube.com/watch?v=D2Qcwjidxns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QivnOnDulBdd",
        "outputId": "09f3d99f-fcab-4ca5-d169-579e2ff05652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=EKkZ8yVu2yg\n",
            "[youtube] EKkZ8yVu2yg: Downloading webpage\n",
            "[youtube] EKkZ8yVu2yg: Downloading android sdkless player API JSON\n",
            "[youtube] EKkZ8yVu2yg: Downloading tv client config\n",
            "[youtube] EKkZ8yVu2yg: Downloading tv player API JSON\n",
            "[youtube] EKkZ8yVu2yg: Downloading web safari player API JSON\n",
            "[youtube] EKkZ8yVu2yg: Downloading m3u8 information\n",
            "[info] EKkZ8yVu2yg: Downloading 1 format(s): 251\n",
            "[download] Sleeping 5.00 seconds as required by the site...\n",
            "[download] Destination: audio2.webm\n",
            "\u001b[K[download] 100% of    1.25MiB in \u001b[1;37m00:00:00\u001b[0m at \u001b[0;32m2.57MiB/s\u001b[0m\n",
            "[ExtractAudio] Destination: audio2.mp3\n",
            "Deleting original file audio2.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "if (os.path.exists(\"/content/audio2.mp3\")):\n",
        "  os.remove(\"/content/audio2.mp3\")\n",
        "else:\n",
        "  pass\n",
        "!yt-dlp -x --audio-format mp3 --output \"audio2.mp3\" https://www.youtube.com/watch?v=EKkZ8yVu2yg #try replacing the link here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YYe6m9onH1-",
        "outputId": "22017bbe-6416-4cd9-8ac5-a8eedeea55f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Chinese\n",
            "[00:00.000 --> 00:14.400] 一个是给我更多的项目的了解\n",
            "[00:14.400 --> 00:16.320] 一个是在我知识方面\n",
            "[00:16.320 --> 00:18.580] 会让我有更广泛的学习\n",
            "[00:18.580 --> 00:21.880] 它也是帮助我们结合AI和教育之间\n",
            "[00:21.880 --> 00:23.600] 一个很好的一个桥梁\n",
            "[00:23.600 --> 00:26.140] 所以在我了解到这个课程的时候\n",
            "[00:26.140 --> 00:27.380] 就非常的感兴趣\n",
            "[00:27.380 --> 00:28.940] 科技之类读书\n",
            "[00:28.940 --> 00:33.520] 现在社会都对人文智能有很广泛的应用\n",
            "[00:33.520 --> 00:36.400] 所以我想通过这方面的课程\n",
            "[00:36.400 --> 00:40.260] 可以有我深入对这个专业的认识\n",
            "[00:40.260 --> 00:41.740] 我是跟他讲我后面的规划\n",
            "[00:41.740 --> 00:44.020] 他也是会给我一些相对的建议\n",
            "[00:44.020 --> 00:45.720] 说他能给予我什么帮助\n",
            "[00:45.720 --> 00:47.780] 我需要达到一种什么样的程度\n",
            "[00:47.780 --> 00:49.420] 这边是小组讨论\n",
            "[00:49.420 --> 00:50.200] 你要有一个小组\n",
            "[00:50.200 --> 00:51.640] 然后你要去做一些discord\n",
            "[00:51.640 --> 00:53.980] 我觉得这个对于一些思维的碰撞\n",
            "[00:53.980 --> 00:54.900] 这个是非常好\n",
            "[00:54.900 --> 00:56.020] 他里面学的一些东西\n",
            "[00:56.020 --> 00:58.440] 和我们现在学的AI是非常的接触\n",
            "[00:58.440 --> 00:58.860] 我觉得\n",
            "[00:58.860 --> 01:00.140] 这是我的一个兴趣\n",
            "[01:00.140 --> 01:04.500] 他也都很希望能够再练习人工智能会不会\n",
            "[01:04.500 --> 01:07.300] 令到他在不同的专业之后\n",
            "[01:07.300 --> 01:09.860] 多一个人工智能的基础\n",
            "[01:09.860 --> 01:12.500] 去让他在达速社会的时候\n",
            "[01:12.500 --> 01:14.380] 能够准备得更加好\n"
          ]
        }
      ],
      "source": [
        "!whisper \"/content/audio2.mp3\" --model large --fp16 False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4dRdNMksRcs"
      },
      "source": [
        "Translate non-English YouTube videos into English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BNMFfp8sXAm",
        "outputId": "27efb9f9-7bd4-407b-d739-70ec7a4f1325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Chinese\n",
            "[00:00.000 --> 00:11.000]  What is the most important thing for you to learn about AI?\n",
            "[00:11.000 --> 00:14.000]  One is to learn more about the project\n",
            "[00:14.000 --> 00:18.000]  The other is to learn more about my knowledge\n",
            "[00:18.000 --> 00:23.000]  It is also a good bridge between AI and education\n",
            "[00:23.000 --> 00:27.000]  So when I learned about this course, I was very interested\n",
            "[00:27.000 --> 00:29.000]  I studied in science and technology\n",
            "[00:29.000 --> 00:33.000]  Now the society has a wide range of applications for AI\n",
            "[00:33.000 --> 00:40.000]  So I want to learn more about AI through this course\n",
            "[00:40.000 --> 00:42.000]  I talked to him about my future plans\n",
            "[00:42.000 --> 00:44.000]  He also gave me some relative suggestions\n",
            "[00:44.000 --> 00:46.000]  What kind of help can he give me?\n",
            "[00:46.000 --> 00:48.000]  To what extent do I need to achieve?\n",
            "[00:48.000 --> 00:50.000]  This is a group discussion\n",
            "[00:50.000 --> 00:52.000]  You have to have a group and then you have to do some discussion\n",
            "[00:52.000 --> 00:55.000]  I think this is very good for some thoughts\n",
            "[00:55.000 --> 00:56.000]  What he learned in it\n",
            "[00:56.000 --> 00:57.000]  And what we are learning now\n",
            "[00:57.000 --> 00:58.000]  AI is very interesting\n",
            "[00:58.000 --> 01:00.000]  I think this is what I am interested in\n",
            "[01:00.000 --> 01:03.000]  He also hopes to be able to learn more about AI\n",
            "[01:03.000 --> 01:05.000]  Will he be able to learn more about AI\n",
            "[01:05.000 --> 01:07.000]  After he is in a different profession\n",
            "[01:07.000 --> 01:09.000]  Add another foundation of AI\n",
            "[01:09.000 --> 01:12.000]  To let him be able to meet the society again\n",
            "[01:12.000 --> 01:14.000]  Then he will be able to prepare better\n",
            "[01:14.000 --> 01:18.000]  How long will be the last time you talk to me?\n"
          ]
        }
      ],
      "source": [
        "!whisper \"/content/audio2.mp3\" --model large --task translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8f-IRCVs5Ss"
      },
      "source": [
        "*Extra: View all available options in Whisper*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksfx3wbbsukc",
        "outputId": "bc89f6e6-11e6-46c2-c0e2-061630a0280c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
            "               [--output_dir OUTPUT_DIR]\n",
            "               [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
            "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "               [--temperature TEMPERATURE] [--best_of BEST_OF]\n",
            "               [--beam_size BEAM_SIZE] [--patience PATIENCE]\n",
            "               [--length_penalty LENGTH_PENALTY]\n",
            "               [--suppress_tokens SUPPRESS_TOKENS]\n",
            "               [--initial_prompt INITIAL_PROMPT]\n",
            "               [--carry_initial_prompt CARRY_INITIAL_PROMPT]\n",
            "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "               [--fp16 FP16]\n",
            "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "               [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "               [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "               [--word_timestamps WORD_TIMESTAMPS]\n",
            "               [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "               [--append_punctuations APPEND_PUNCTUATIONS]\n",
            "               [--highlight_words HIGHLIGHT_WORDS]\n",
            "               [--max_line_width MAX_LINE_WIDTH]\n",
            "               [--max_line_count MAX_LINE_COUNT]\n",
            "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
            "               [--clip_timestamps CLIP_TIMESTAMPS]\n",
            "               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n",
            "               audio [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio                 audio file(s) to transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         name of the Whisper model to use (default: turbo)\n",
            "  --model_dir MODEL_DIR\n",
            "                        the path to save model files; uses ~/.cache/whisper by\n",
            "                        default (default: None)\n",
            "  --device DEVICE       device to use for PyTorch inference (default: cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "                        directory to save the outputs (default: .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "                        format of the output file; if not specified, all\n",
            "                        available formats will be produced (default: all)\n",
            "  --verbose VERBOSE     whether to print out the progress and debug messages\n",
            "                        (default: True)\n",
            "  --task {transcribe,translate}\n",
            "                        whether to perform X->X speech recognition\n",
            "                        ('transcribe') or X->English translation ('translate')\n",
            "                        (default: transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "                        language spoken in the audio, specify None to perform\n",
            "                        language detection (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "                        temperature to use for sampling (default: 0)\n",
            "  --best_of BEST_OF     number of candidates when sampling with non-zero\n",
            "                        temperature (default: 5)\n",
            "  --beam_size BEAM_SIZE\n",
            "                        number of beams in beam search, only applicable when\n",
            "                        temperature is zero (default: 5)\n",
            "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
            "                        https://arxiv.org/abs/2204.05424, the default (1.0) is\n",
            "                        equivalent to conventional beam search (default: None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "                        optional token length penalty coefficient (alpha) as\n",
            "                        in https://arxiv.org/abs/1609.08144, uses simple\n",
            "                        length normalization by default (default: None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "                        comma-separated list of token ids to suppress during\n",
            "                        sampling; '-1' will suppress most special characters\n",
            "                        except common punctuations (default: -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "                        optional text to provide as a prompt for the first\n",
            "                        window. (default: None)\n",
            "  --carry_initial_prompt CARRY_INITIAL_PROMPT\n",
            "                        if True, prepend initial_prompt to every internal\n",
            "                        decode() call. May reduce the effectiveness of\n",
            "                        condition_on_previous_text (default: False)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "                        if True, provide the previous output of the model as a\n",
            "                        prompt for the next window; disabling may make the\n",
            "                        text inconsistent across windows, but the model\n",
            "                        becomes less prone to getting stuck in a failure loop\n",
            "                        (default: True)\n",
            "  --fp16 FP16           whether to perform inference in fp16; True by default\n",
            "                        (default: True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "                        temperature to increase when falling back when the\n",
            "                        decoding fails to meet either of the thresholds below\n",
            "                        (default: 0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "                        if the gzip compression ratio is higher than this\n",
            "                        value, treat the decoding as failed (default: 2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "                        if the average log probability is lower than this\n",
            "                        value, treat the decoding as failed (default: -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "                        if the probability of the <|nospeech|> token is higher\n",
            "                        than this value AND the decoding has failed due to\n",
            "                        `logprob_threshold`, consider the segment as silence\n",
            "                        (default: 0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "                        (experimental) extract word-level timestamps and\n",
            "                        refine the results based on them (default: False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation\n",
            "                        symbols with the next word (default: \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation\n",
            "                        symbols with the previous word (default:\n",
            "                        \"'.。,，!！?？:：”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "                        (requires --word_timestamps True) underline each word\n",
            "                        as it is spoken in srt and vtt (default: False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "                        (requires --word_timestamps True) the maximum number\n",
            "                        of characters in a line before breaking the line\n",
            "                        (default: None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "                        (requires --word_timestamps True) the maximum number\n",
            "                        of lines in a segment (default: None)\n",
            "  --max_words_per_line MAX_WORDS_PER_LINE\n",
            "                        (requires --word_timestamps True, no effect with\n",
            "                        --max_line_width) the maximum number of words in a\n",
            "                        segment (default: None)\n",
            "  --threads THREADS     number of threads used by torch for CPU inference;\n",
            "                        supercedes MKL_NUM_THREADS/OMP_NUM_THREADS (default:\n",
            "                        0)\n",
            "  --clip_timestamps CLIP_TIMESTAMPS\n",
            "                        comma-separated list start,end,start,end,...\n",
            "                        timestamps (in seconds) of clips to process, where the\n",
            "                        last end timestamp defaults to the end of the file\n",
            "                        (default: 0)\n",
            "  --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD\n",
            "                        (requires --word_timestamps True) skip silent periods\n",
            "                        longer than this threshold (in seconds) when a\n",
            "                        possible hallucination is detected (default: None)\n"
          ]
        }
      ],
      "source": [
        "!whisper --help"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}